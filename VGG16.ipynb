{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5jOL/Zpfs3+yICcxQexYu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vrhughes/DS4002-Project3/blob/main/VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing"
      ],
      "metadata": {
        "id": "VOF6YtZBqft6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FE7BlNp-SzDJ"
      },
      "outputs": [],
      "source": [
        "# Basic importing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing from example code\n",
        "import os\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from tensorflow.keras.layers import Activation, BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPool2D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "8yw_b2tNTDCC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Data"
      ],
      "metadata": {
        "id": "5fA-vH9Xqj8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting kaggle path\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"puneet6060/intel-image-classification\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwNdGfSQUq3X",
        "outputId": "c4c0ffeb-3be4-4dd9-cffc-2cfb28e95300"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/intel-image-classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# paths of data\n",
        "test_path = '/kaggle/input/intel-image-classification/seg_test/seg_test'\n",
        "train_path = '/kaggle/input/intel-image-classification/seg_train/seg_train'"
      ],
      "metadata": {
        "id": "-bedpyrWUi1y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking what is in the folders\n",
        "for folder in  os.listdir(train_path):\n",
        "    files = glob(pathname= str(train_path + '/' + folder + '/*.jpg'))\n",
        "    print(f'Found {len(files)} in folder {folder}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocoxrb5WVk3e",
        "outputId": "723ee000-54d7-45bb-b70c-8874a680aaf0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2512 in folder mountain\n",
            "Found 2382 in folder street\n",
            "Found 2191 in folder buildings\n",
            "Found 2274 in folder sea\n",
            "Found 2271 in folder forest\n",
            "Found 2404 in folder glacier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seeing what folders are in the directory\n",
        "os.listdir(train_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CksRpuQvXeC2",
        "outputId": "ccd36470-8c2b-47b5-d5b6-83706894674d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mountain', 'street', 'buildings', 'sea', 'forest', 'glacier']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deleting 'street'"
      ],
      "metadata": {
        "id": "PTPFa3gFqm_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleting the street folders from the train and test data\n",
        "\n",
        "# Define the folders you want to include\n",
        "folders = ['buildings', 'forest', 'glacier', 'mountain', 'sea']\n",
        "\n",
        "folder_labels = {folder_name:i for i, folder_name in enumerate(folders)}\n",
        "print(folder_labels)\n",
        "\n",
        "numbered_folders = len(folders)\n",
        "\n",
        "IMAGE_SIZE = (150, 150)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjSvoIigXoOh",
        "outputId": "d1b54ce1-ddf9-438c-a249-6bad507fb05c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'buildings': 0, 'forest': 1, 'glacier': 2, 'mountain': 3, 'sea': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ImageDataGenerator"
      ],
      "metadata": {
        "id": "4g01KmZ3qrdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up ImageDataGenerator (can add augmentation later)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "#                                   zoom_range=0.25,\n",
        "#                                   validation_split=0.2,\n",
        "#                                   width_shift_range=0.15,\n",
        "#                                   height_shift_range=0.15,\n",
        "#                                   horizontal_flip = True,\n",
        "#                                   vertical_flip = False,\n",
        "#                                   fill_mode='nearest')"
      ],
      "metadata": {
        "id": "xWkYiXIIlo9z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data loader (excluding street)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size = IMAGE_SIZE,     # sizing data\n",
        "    batch_size = 32,              # this is default, can change if needed\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'training',\n",
        "    classes = folders, # <<<<<<< doesn't include street\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "# Validation loader\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size = IMAGE_SIZE,\n",
        "    batch_size = 32,              # try 128?\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'validation',\n",
        "    classes = folders, # <<<<<<< doesn't include street\n",
        "    shuffle = False # ???????????????? why\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qohANyGil7Hq",
        "outputId": "efb8aa8b-5984-4787-ffe3-151d684967c5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9324 images belonging to 5 classes.\n",
            "Found 2328 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test generator\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size = IMAGE_SIZE,\n",
        "    batch_size = 32,\n",
        "    class_mode = 'categorical',\n",
        "    classes = folders, # <<<<<<< doesn't include street\n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQx8d5BopGUb",
        "outputId": "1fe413c1-93b7-4b27-b0ed-c2006001d7a7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2499 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building VGG16 Model"
      ],
      "metadata": {
        "id": "YxcBufzLp1t-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/code/janvichokshi/transfer-learning-cnn-resnet-vgg16-iceptionv3#Preparing-the-dataset"
      ],
      "metadata": {
        "id": "gFbKueMGqZ2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_dataset(path, label):\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    all_images_path = glob(path+'/*.jpg')\n",
        "    for img_path in all_images_path:\n",
        "        img = load_img(img_path, target_size=(150, 150))\n",
        "        img = img_to_array(img)\n",
        "        img = img/255.0\n",
        "        x_train.append(img)\n",
        "        y_train.append(label)\n",
        "    return np.array(x_train), np.array(y_train)"
      ],
      "metadata": {
        "id": "PzskP9dEqZet"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX_building, trainY_building  = prep_dataset(\"../input/intel-image-classification/seg_train/seg_train/buildings/\",0)\n",
        "trainX_forest, trainY_forest  = prep_dataset(\"../input/intel-image-classification/seg_train/seg_train/forest/\",1)\n",
        "trainX_glacier, trainY_glacier  = prep_dataset(\"../input/intel-image-classification/seg_train/seg_train/glacier/\",2)\n",
        "trainX_mount, trainY_mount  = prep_dataset(\"../input/intel-image-classification/seg_train/seg_train/mountain/\",3)\n",
        "trainX_sea, trainY_sea  = prep_dataset(\"../input/intel-image-classification/seg_train/seg_train/sea/\",4)\n",
        "\n",
        "print('train building shape ', trainX_building.shape, trainY_building.shape)\n",
        "print('train forest shape ', trainX_forest.shape, trainY_forest.shape)\n",
        "print('train glacier shape ', trainX_glacier.shape, trainY_glacier.shape)\n",
        "print('train mountain shape ', trainX_mount.shape, trainY_mount.shape)\n",
        "print('train sea shape ', trainX_sea.shape, trainY_sea.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hke9DNhvsGL3",
        "outputId": "58ca9bc7-97fc-4d2d-842d-1153f944df81"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train building shape  (0,) (0,)\n",
            "train forest shape  (0,) (0,)\n",
            "train glacier shape  (0,) (0,)\n",
            "train mountain shape  (0,) (0,)\n",
            "train sea shape  (0,) (0,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting pretrained model\n",
        "pretrained_model = VGG16(\n",
        "    input_shape = (150, 150, 3),\n",
        "    include_top = False,\n",
        "    weights = 'imagenet'\n",
        ")\n",
        "\n",
        "for layer in pretrained_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "RxW1q77Elhyh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pretained_model.summary()\n",
        "last_layer = pretrained_model.get_layer('block5_pool')\n",
        "print('last layer of vgg : output shape: ', last_layer.output_shape)\n",
        "last_output= last_layer.output\n",
        "\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(6, activation='softmax')(x)\n",
        "\n",
        "model_vgg = Model(pretrained_model.input, x)\n",
        "\n",
        "\n",
        "model_vgg.compile(optimizer = RMSprop(lr=0.0001),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['acc'])"
      ],
      "metadata": {
        "id": "PtvP0f0fq7i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x2SB6z3Hp9JB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}